{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Experiment_framework.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Bi6-f69y8ljb",
        "wpQni_3IVoM9",
        "mwdjjV56W5ay",
        "0mAggVQf8zlY",
        "V0ZrZBOEywld",
        "L-Q-zDY_vWWq",
        "d19TrjrSo--s",
        "Flyi--SpvsJN"
      ]
    },
    "interpreter": {
      "hash": "a7d86a09c064b5c4b19f4874f0bf2cbb84d6cd074d919219f9cbe65e1ae0789d"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit ('litmus-cars': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7XbLCXGkll9"
      },
      "source": [
        "# Experiment framework\n",
        "This notebook gives an example of how the framework can be used to train and evaluate models on standard vehicle identification datasets. The framework can be invoked via the CLI or using python classes. \n",
        "\n",
        "This notebook shows how the experiments can be run using the CLI\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LODD6w9ixlT"
      },
      "source": [
        "## Colab specific\n",
        "Modify and run these cells to prepare the colab environment for the project\n",
        "- Setup integration with google drive\n",
        "    - Needs these paths: mount point, Dataset storage path, checkpoint storage path, prediction storage path\n",
        "- Setup content folder as git repo and pull codebase from github"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyJP0vI_IBzH"
      },
      "source": [
        "### The project expects a few folders in the root directory. Since the colab environment is transient, these folders need to be recreated everytime a fresh runtime is started. The below cell creates links to the source folder present in google drive:\n",
        "- checkpoints  (For storing logs and model checkpoints)\n",
        "- predictions (For storing the predictions while evaluating)\n",
        "- carzam (For downloading the compressed dataset files, used in the setup_dataset method)\n",
        "- dataset (NOT CREATED HERE, Running setup_dataset scripts creates this folder and copies the extracted dataset files)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2LEmL4hGhea"
      },
      "source": [
        "import os\n",
        "# Path constants\n",
        "STORAGE_ROOT='/content/drive'                                       # google drive mount point\n",
        "CARZAM_ROOT= os.path.join(STORAGE_ROOT, 'MyDrive/Gatech/CARZAM')    # Project root within drive \n",
        "CHECKPOINT_ROOT=os.path.join(CARZAM_ROOT, 'checkpoints')            # Experiment root within project\n",
        "PREDICTION_ROOT=os.path.join(CARZAM_ROOT, 'predictions')\n",
        "DATASET_ROOT=os.path.join(CARZAM_ROOT, 'Datasets')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5yV1Fu8H2Dn"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(STORAGE_ROOT)\n",
        "!mkdir -p \"{CHECKPOINT_ROOT}\"\n",
        "!mkdir -p \"{PREDICTION_ROOT}\"\n",
        "!ln -s \"{CHECKPOINT_ROOT}\" \"checkpoints\"\n",
        "!ln -s \"{PREDICTION_ROOT}\" \"predictions\"\n",
        "!ln -s \"{CARZAM_ROOT}\" \"carzam\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqkktIOnqJW9"
      },
      "source": [
        "### Setup up codebase from github\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkfMSCSINhCn"
      },
      "source": [
        "Init the current folder as a git repo and link it to remote github repo before pulling. This allows us to clone into a folder with existing files. We also set the remote as upstream to allow changes to be done from colab to the project files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31_9TaKlrEXP"
      },
      "source": [
        "!git init\n",
        "!git remote add origin \"https://github.com/piyengar/vehicle-predictor.git\" \n",
        "!git fetch\n",
        "!git checkout develop\n",
        "# !git branch --set-upstream-to=origin/develop develop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44VKK3qpRTK3"
      },
      "source": [
        "## Install project\n",
        "This will add the project and packages to the python env"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S63FIRgN5csf"
      },
      "source": [
        "# %%capture --no-stderr\n",
        "!pip install -e ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjrrNVorRTK4"
      },
      "source": [
        "## Define dataset location \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmTMnlx-RTK4"
      },
      "source": [
        "DATASET_ROOT='./dataset'\n",
        "# Set a name for the experiment, This will be used to create a folder for storing the logs, predictions and model checkpoints\n",
        "EXPERIMENT_NAME= 'brand'\n",
        "# Path where the experiment script exists\n",
        "EXPERIMENT_SCRIPT= \"experiments/brand/train_brand.py\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWtBQUY8tNZn"
      },
      "source": [
        "### Download and setup datasets\n",
        "The below method downloads and extracts the datasets into the dataset folder in the project root. The table also gives an estimate of the space each dataset takes\n",
        "\n",
        "| Dataset         |  GB |\n",
        "|-----------------|----:|\n",
        "| VeRi_with_plate | 1.1 |\n",
        "| CompCars        | 2.5 |\n",
        "| Cars196         | 1.9 |\n",
        "| BoxCars116k     | 9.2 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkivVeekwjRu"
      },
      "source": [
        "### CompCars Dataset setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBGH7TeoDzEe"
      },
      "source": [
        "\n",
        "%%capture --no-stderr\n",
        "from getpass import getpass\n",
        "!python setup_dataset.py download -n COMP_CARS -s gdrive -d ./dataset_source\n",
        "cc_pass = getpass(\"Password:\")\n",
        "os.environ['VP_COMP_CARS_PASS'] = cc_pass\n",
        "!python setup_dataset.py setup -n COMP_CARS -s ./dataset_source -d {DATASET_ROOT} "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRRLxI-pE-Zp"
      },
      "source": [
        "### BoxCars116k dataset Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yH3clmBIE-Zy"
      },
      "source": [
        "%%capture --no-stderr\n",
        "!python setup_dataset.py download -n BOXCARS116K -s gdrive -d ./dataset_source\n",
        "!python setup_dataset.py setup -n BOXCARS116K -s ./dataset_source -d {DATASET_ROOT}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn55y9MYEiD_"
      },
      "source": [
        "### Cars196 dataset Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzzsi_7hEiEA"
      },
      "source": [
        "# %%capture --no-stderr\n",
        "!python setup_dataset.py download -n CARS196 -s gdrive -d ./dataset_source\n",
        "!python setup_dataset.py setup -n CARS196 -s ./dataset_source -d {DATASET_ROOT}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YojqUjZGlKEv"
      },
      "source": [
        "### VeRi dataset Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYMo9OILlKE4"
      },
      "source": [
        "# %%capture --no-stderr\n",
        "!python setup_dataset.py download -n VERI -s gdrive -d ./dataset_source\n",
        "!python setup_dataset.py setup -n VERI -s ./dataset_source -d {DATASET_ROOT}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBNyVyQvlKiP"
      },
      "source": [
        "### VRIC dataset Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMnqj1YwlKiP"
      },
      "source": [
        "# %%capture --no-stderr\n",
        "!python setup_dataset.py download -n VRIC -s gdrive -d ./dataset_source\n",
        "!python setup_dataset.py setup -n VRIC -s ./dataset_source -d {DATASET_ROOT}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qV2rQCdRwe1N"
      },
      "source": [
        "### VehicleID Dataset setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_Y8v-A5wZxg"
      },
      "source": [
        "# %%capture --no-stderr\n",
        "!python setup_dataset.py download -n VEHICLE_ID -s gdrive -d ./dataset_source\n",
        "from getpass import getpass\n",
        "veh_pass = getpass(\"Password:\")\n",
        "os.environ['VP_VEHICLE_ID_PASS'] = veh_pass\n",
        "!python setup_dataset.py setup -n VEHICLE_ID -s ./dataset_source -d {DATASET_ROOT}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ksgw1oVAt_4"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqublLfcxXNY"
      },
      "source": [
        "### Training params\n",
        "Change the training hyper params as required"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D56zfDySJbb7"
      },
      "source": [
        "# one of : VEHICLE_ID, BOXCARS116K, CARS196, COMBINED, COMP_CARS\n",
        "# train_dataset_type = 'CARS196'\n",
        "train_dataset_type = 'BOXCARS116K'\n",
        "# train_dataset_type = 'VEHICLE_ID'\n",
        "# train_dataset_type = 'COMP_CARS'\n",
        "# train_dataset_type = 'COMBINED'\n",
        "test_dataset_type = train_dataset_type\n",
        "# Learning rate/eta0\n",
        "lr=4e-2\n",
        "lr2=1e-5 # squeezenet \n",
        "lr_step=1\n",
        "lr_step_factor=0.9\n",
        "\n",
        "#Early stop patience\n",
        "patience = 4\n",
        "\n",
        "batch_size=128\n",
        "max_epochs=1\n",
        "\n",
        "# \"resnet18\",\n",
        "# \"resnet50\",\n",
        "# \"resnet152\",\n",
        "# \"mobilenetv3-small\",\n",
        "# \"efficientnet-b0\",\n",
        "# \"squeezenet\",\n",
        "model_arch=\"efficientnet-b0\"\n",
        "\n",
        "# development\n",
        "is_dev_run=False\n",
        "\n",
        "# The number of gpus to use for training. The below line sets it to the num of available gpus\n",
        "num_gpus = -1\n",
        "num_dataloader_workers = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qn-NHRqwd8dm"
      },
      "source": [
        "### Dataset statistics\n",
        "Prints out the class distribution statistics for the train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxYNvBqtFiPe"
      },
      "source": [
        "! python {EXPERIMENT_SCRIPT} train_stats test_stats --train_dataset {train_dataset_type} --test_dataset {test_dataset_type} --data_dir {DATASET_ROOT}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MO-kXOa22LOm"
      },
      "source": [
        "### Tune Learning Rate\n",
        "Helps us find an approximate learning rate for training by running heuristics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFo_e1V7RTK9"
      },
      "source": [
        "! python experiments/brand/train_brand.py tune --train_dataset {train_dataset_type} --model_arch {model_arch}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubvW3LGSupmt"
      },
      "source": [
        "---\n",
        "## Train\n",
        "Train the model defined in the experiment using the \"brand\" experiment as an example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yT8_rj00w1-"
      },
      "source": [
        "! python {EXPERIMENT_SCRIPT} train \\\n",
        "    --model_arch \"efficientnet-b0\" \\\n",
        "    --max_epochs {max_epochs} \\\n",
        "    --gpus -1 \\\n",
        "    --train_dataset {train_dataset_type} \\\n",
        "    --data_dir {DATASET_ROOT}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuRYlMvVv3Q-"
      },
      "source": [
        "---\n",
        "## Visualize\n",
        "The logs will be stored in \\<checkpoints>/\\<EXPERIMENT_NAME>/lightning_logs/*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgmkxSSqv6tk"
      },
      "source": [
        "# Start tensorboard.\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir checkpoints/{EXPERIMENT_NAME}/lightning_logs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEksf22i7x3K"
      },
      "source": [
        "## Evaluate Predictions\n",
        "We run evaluations in two stages. First the predictions are stored in an output file. Then, the prediction files are used to compute the metrics. This gives us the flexibility to checkpoint our progress as some of them might take long even with GPUs and might get aborted due to environment constraints."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8NDbiea7yqv"
      },
      "source": [
        "### Predict\n",
        "Runs predictions on the dataset's test data and saves it in the prediction folder. The get_conf_data method generates the persistence path and model path based on input params in a deterministic fashion\n",
        "\n",
        "The prediction loads the model from the provided \\*.ckpt file .\n",
        "\n",
        "The predictions are stored into the file provided by the `--prediction_file_name` arg or  \\<predictions\\>/\\<EXPERIMENT_NAME>/\\<test_dataset>\\_\\<model_checkpoint_file>\\_\\<time.time()>.txt\n",
        "\n",
        "Note down the prediction file path being printed and use it in the next step. \n",
        "\n",
        "`TIP: you can call both the predict and evaluate commands in a single step and skip providing the prediction file arg. The prediction file will still be saved in the file path mentioned above`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lp6WQ2vT0ECc"
      },
      "source": [
        "! python {EXPERIMENT_SCRIPT} predict --model_arch \"efficientnet-b0\" \\\n",
        "    --gpus -1 --test_dataset VEHICLE_ID \\\n",
        "    --model_checkpoint_file \"checkpoints/brand/lightning_logs/version_13/checkpoints/epoch=0-step=738.ckpt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "km7g_p7d726O"
      },
      "source": [
        "### Evaluate\n",
        "Evaluates various metrics from stored prediction files and stores it in files. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GkdRgLe74Hf"
      },
      "source": [
        "! python {EXPERIMENT_SCRIPT} evaluate \\\n",
        "    --test_dataset VEHICLE_ID \\\n",
        "    --prediction_file_path \"predictions/brand/prediction_file.txt\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}